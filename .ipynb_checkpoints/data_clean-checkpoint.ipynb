{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 去除主题，情感词都为空的行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_excel('./data/origin.xlsx')\n",
    "data = data.fillna(\"$$$\")\n",
    "duty_data = data[data.sentiment_word == \"$$$\"]\n",
    "clean_data = data.drop(data[data.sentiment_word == \"$$$\"].index)\n",
    "\n",
    "# 情感词为空的数据\n",
    "duty_data.to_csv(\"./data/duty_data.csv\", sep='\\t', index=None, encoding=\"utf8\")\n",
    "# 干净的数据\n",
    "clean_data.to_csv(\"./data/clean_data.csv\", sep='\\t', index=None, encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "clean_data = pd.read_csv(\"./data/clean_data.csv\", sep='\\t')\n",
    "data = clean_data.sample(frac = 1)\n",
    "percent = int(data.shape[0] * 0.9)\n",
    "train_data = data.iloc[:percent]\n",
    "test_data = data.iloc[percent:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.to_csv(\"./data/train.csv\", sep=\"\\t\", index=None)\n",
    "test_data.to_csv('./data/test.csv', sep=\"\\t\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 检测content分词后，是否能保留情感词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import thulac\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "train_data = pd.read_csv('./data/clean_data.csv', sep='\\t')\n",
    "seg = thulac.thulac(user_dict='./data/test.txt')\n",
    "# row = train_data.iloc[1]\n",
    "# content = row[\"content\"]\n",
    "# sentiment_words = row[\"sentiment_word\"]\n",
    "\n",
    "\n",
    "\n",
    "# content_data = train_data.loc[:,'content']\n",
    "\n",
    "# #使用ltp依次进行分词、词性标注、句法分析\n",
    "# # -*- coding: utf-8 -*-\n",
    "# from pyltp import Segmentor\n",
    "# from pyltp import Postagger\n",
    "# from pyltp import NamedEntityRecognizer\n",
    "# from pyltp import Parser\n",
    "\n",
    "# import os\n",
    "# LTP_DATA_DIR = '/home/zwl/pyltp-master/ltp_data'  # ltp模型目录的路径\n",
    "# cws_model_path = os.path.join(LTP_DATA_DIR, 'cws.model')  # 分词模型路径，模型名称为`cws.model`\n",
    "\n",
    "# #分词\n",
    "# segmentor = Segmentor()  # 初始化实例\n",
    "# segmentor.load_with_lexicon(cws_model_path, './data/test.txt')  # 加载模型\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg_res = []\n",
    "word_res = []\n",
    "cnt_res = []\n",
    "def lexcial_coverage(content, words):\n",
    "    seg_words = seg.cut(content)\n",
    "#     print(list(seg_words))\n",
    "    no_pos_words = [item[0] for item in seg_words ]\n",
    "    seg_res.append(no_pos_words)\n",
    "    words_list = words.split(';')\n",
    "    word_res.append(words_list)\n",
    "#     print(no_pos_words)\n",
    "#     print(words_list)\n",
    "#     print('******\\n')\n",
    "    cnt = 0\n",
    "    for word in words_list:\n",
    "        try:\n",
    "            tmp = no_pos_words.index(word)\n",
    "            cnt = cnt + 1\n",
    "        except:\n",
    "            pass\n",
    "    cnt_res.append(cnt)\n",
    "    return cnt / len(words_list)\n",
    "res = 0\n",
    "i = 0\n",
    "for row in train_data.values:\n",
    "    print(i)\n",
    "    i = i + 1\n",
    "    content = row[1]\n",
    "    words = row[3]\n",
    "    percent = lexcial_coverage(content, words)\n",
    "    res = res + percent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_series = pd.Series(seg_res)\n",
    "word_series = pd.Series(word_res)\n",
    "cnt_series = pd.Series(cnt_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete(s):\n",
    "    res = ''\n",
    "    i = 0\n",
    "    for item in s:\n",
    "        if i == 0:\n",
    "            res = res + item\n",
    "        else:\n",
    "            res = res + ',' + item\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "haha = pd.DataFrame({\"seg\":seg_series, \"word\":word_series, \"cnt\":cnt_series})\n",
    "def delete(s):\n",
    "    res = ''\n",
    "    i = 0\n",
    "    for item in s:\n",
    "\n",
    "        if i == 0:\n",
    "            res = res + item\n",
    "        else:\n",
    "            res = res + '\\t' + item\n",
    "        i = i + 1\n",
    "    return res\n",
    "haha[\"seg\"] = haha[\"seg\"].apply(delete)\n",
    "haha[\"word\"] = haha[\"word\"].apply(delete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 重新对content分词, 生成序列标注的数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded succeed\n",
      "successfully cut file ./data/validation_content.csv!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = pd.read_csv('./data/validation.csv', delimiter=',')\n",
    "content = pd.DataFrame(data[\"content\"])\n",
    "content.to_csv('./data/validation_content.csv', header=None, index=None)\n",
    "import thulac\n",
    "model = thulac.thulac(seg_only=True, user_dict='./data/dict.txt')\n",
    "model.cut_f(input_file='./data/validation_content.csv', output_file='./data/validation_seg_content.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_content = pd.read_csv('./data/validation_seg_content.csv', delimiter='\\t', header=None)\n",
    "\n",
    "sentiment_set = pd.read_csv('./data/sentiment.csv', header=None, delimiter='\\t')\n",
    "theme_set = pd.read_csv('./data/theme.csv', header=None, delimiter='\\t')\n",
    "\n",
    "\n",
    "sentiment = set()\n",
    "for item in sentiment_set.values:\n",
    "    sentiment.add(item[0])\n",
    "theme = set()\n",
    "for item in theme_set.values:\n",
    "    theme.add(item[0])\n",
    "\n",
    "def list_to_str(l):\n",
    "    res = \"\"\n",
    "    for i in range(len(l)):\n",
    "        if i == 0:\n",
    "            res = res + l[i]\n",
    "        else:\n",
    "            res = res + \" \" + l[i]\n",
    "    return res\n",
    "haha = []\n",
    "with open('./data/validation_seg_content.csv', 'r') as f:\n",
    "    for (num,value) in enumerate(f):\n",
    "        value = value.strip()\n",
    "        words = value.split(' ')\n",
    "        res = []\n",
    "        pos = 0\n",
    "        for word in words:\n",
    "            if words == \"\\n\":\n",
    "                continue\n",
    "            if word in sentiment:\n",
    "                res.append(word + '/S')\n",
    "            elif word in theme:\n",
    "                res.append(word + '/T')\n",
    "            else:\n",
    "                res.append(word + '/O')\n",
    "        target = [list_to_str(res)]\n",
    "        haha.append(target)\n",
    "\n",
    "\n",
    "\n",
    "haha = pd.DataFrame(haha)\n",
    "\n",
    "haha\n",
    "\n",
    "haha.to_csv('./data/validation_target.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>比/O 黑人/O 碳头/O 牙刷/T 好用/S ?/O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>比/O 之前/O 坏/S 的/O 要/O 好/S 些/O ，/O 亮/O 一些/O 。/O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>质量/T 很好/S 用/O 着/O 很/O 舒服/S 感觉/T 有点/O 小贵/S 啊/O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>发货/T 速度/T 很快/S ，/O 东西/T 收到/O 后/O 基本/O 上/O 和/O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/O 、/O 每/O 星期/O 至少/O 两/O 次/S 掉/O 线/T ，/O 一/O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>从/O 中学/O 一直/O 在/O 用/O 的/O ，/O 质量/T 好/S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>此/O 产品/T 太/O 差劲/S 了/O ，/O 没有/O 任何/O 内/O 包装/T ，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>色/O 粉笔/O 也/O 太贵/S 了/O 吧/O ，/O 而且/O 包装/T 也/O 有些...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>买/O 了/O 跟/O 老公/O 一/O 人/O 一个/O ，/O 用/O 下/O 来/O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>亚马逊/T 自营/T 的/O 东西/T 是/O 正品/S ，/O 一贯/O 都/O 不错/S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>气味/T 清香/S ，/O 洗衣/T 洁净/S 。/O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>中间/O 有/O 几/O 页/O 排版/T 有问题/S 有/O 的/O 字/T 看不到/S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>方便/S ，/O 可/O 挂脖/O 上/O ，/O 当/O 项链/O 了/O 。/O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>产品/T 挺软/O ，/O 不/O 过/O 孩子/O 更/O 喜欢/S 自己/O 手指头/O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4/O g/O 移动卡/O ，/O 插/O 进去/O 居然/O 没/O 任何/O 反应/T ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>袜子/T 质量/T 很/O 不错/S ，/O 很/O 满意/S ，/O 这个/O 价/T 格...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>建议/O 看/O 原版/O 难怪/O 在/O 欧洲/O 销量/O 排行/O 第一/O 的/O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>考试/O 内容/T 为0/O 最新/O 题库/O 里面/O 没有/O 一/O 道/O 题/O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rt/O ，/O 搞/O 个/O 驱动/O 太/O 麻烦/S ，/O 烦死/S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>卖/O 了/O 6/O 瓶/T ，/O 没有/O 一/O 瓶/T 不漏/S 的/O ，/O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1/O 。/O 现在/O 一直/O 还/O 在/O 用/O 。/O 。/O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>发/O 过/O 来/O 的/O 是/O 老/O 包装/T ，/O 但是/O 与/O 在/O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1/O ./O 收到/O 货/T 以后/O 内部/O 包装盒/T 上/O 的/O 防伪/O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>用/O 了/O 一/O 周/O ，/O 主要/O 当/O 无/O 线路/T 由/O （/O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>好东西/S ，/O 绝对/O 物有所值/S ！/O 拿/O 回/O 来/O 三/O 天/O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>速度/T 没有/O 广告/T 的/O 那/O 么/O 大/O ，/O 实际/O 测量/T 应...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>我/O 买/O 的/O 亚马逊/T 直营/O ，/O 但是/O 送/O 来/O 的/O 外包...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>买/O 了/O 后/O ，/O 发现/O 公司/T 不/O 能/O 热/O 饭/O 了/O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>很好/S 用/O ，/O 是/O 正品/S ，/O 后悔/S 只/O 买/O 了/O 一/O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>iFrogz/O 爱/O 蛙/O 音效/T 很/O 不错/S ，/O 价/T 格/O 很/O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19970</th>\n",
       "      <td>这里/O 好多/O 的/O 托/O 啊/O ，/O 影响/O 了/O 我/O 的/O 判断/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19971</th>\n",
       "      <td>还/O 没/O 戴/O 着/O 滑雪/O ，/O 效果/T 好坏/O 还/O 不/O 知道/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19972</th>\n",
       "      <td>东西/T 没的说/S ，/O 我/O 家/O 儿子/O 一直/O 吃/O 皇/O 家/O 的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19973</th>\n",
       "      <td>很好/S ！/O 很好/S 用/O 哦/O ！/O 不/O 错哦/O ！/O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19974</th>\n",
       "      <td>内容/T 没有/O 意义/O ，/O 毫无/O 特色/O 。/O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19975</th>\n",
       "      <td>里面/O 的/O 橡胶/T 搓搓/O 就/O 掉/O 了/O ，/O 做工/T 不/O 是/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19976</th>\n",
       "      <td>这个/O 有/O 直营/O 和/O 第三方/O 的/O 都/O 在/O 活动/O 或/O 参...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19977</th>\n",
       "      <td>才/O 用/O 了/O 半/O 个/O 月/O ，/O 后面/O 丢/O 给/O 女朋友/O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19978</th>\n",
       "      <td>很好/S 用/O 很/O 实际/O 的/O 东西/T ，/O 赞/S 。/O 。/O 。/O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19979</th>\n",
       "      <td>味道/T 有点/O 浓/O ，/O 感觉/T 加/O 了/O 很多/S 香精/T ，/O 但...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19980</th>\n",
       "      <td>估计/O 也/O 是/O 随机/O 发放/O 的/O 封面/T ，/O 收到/O 的/O 这...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19981</th>\n",
       "      <td>买/O 的/O 虽然/O 有/O 一/O 年/O 了/O 、/O 但/O 基本/O 上/O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19982</th>\n",
       "      <td>很好/S 跟/O 图片/T 相符/S ，/O 包装/T 完整/S 。/O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19983</th>\n",
       "      <td>才/O 发现/O 发错货/O 了/O ，/O 发成/O 蓝色/O 的/O 了/O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19984</th>\n",
       "      <td>东西/T 还行/S ，/O 便宜/S 又/O 好用/S 。/O 就/O 是/O 送货/T 时...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19985</th>\n",
       "      <td>品胜/O 大/O 品牌/T ，/O 性/O 价/T 比/O 很高/S 。/O 电量/T 很足...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19986</th>\n",
       "      <td>有点/O 不稳/S 质量/T 还可以/S 还可以/S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19987</th>\n",
       "      <td>还/O 没有/O 认真/S 的/O 研究/O ，/O 只/O 拿/O 出/O 来/O 把/O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19988</th>\n",
       "      <td>脏兮兮/S 的/O 像/O 退/O 回去/O 的/O 旧书/O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19989</th>\n",
       "      <td>还好/S ，/O 挺/O 不错/S 的/O ，/O 值得/S 、/O 、/O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19990</th>\n",
       "      <td>自打/O 从/O 卓越/S 买/O 东西/T ，/O 到/O 现在/O 成为/O VIP/O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19991</th>\n",
       "      <td>中国/O PS术/O ，/O 自/O 诞生/O 以/O 来/O 教众/O 不/O 断/O ，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19992</th>\n",
       "      <td>应该/O 还可以/S ，/O 儿童/O 冬季/O 补点/O 还是/O 需要/O 吧/O ，/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19993</th>\n",
       "      <td>和/O 某/O 羊/O 品牌/T 的/O 电热/O 毯比/O ，/O 做工/T 还是/O 差...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>做工/T 扎实/S ，/O 样子/T 漂亮/S ，/O 唯一/O 就是/O 有/O 点/O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>P4/O …/O …/O 但/O 这/O 本/O 书/T 的/O 主要/O 目/O 的/O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>说/O 的/O 是/O 176/O 长/S ，/O 想想/O 可以/S 够/O 一/O 人/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>一般/S ，/O 太软/S 了/O ，/O 躺/O 下去/O 扁扁/O 的/O ，/O 很低...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>很好/S 用/O ，/O 大/O 点/O 就/O 更好/S 了/O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>183/O 70/O 穿/O L/O 正好/S 183/O 70/O 穿/O L/O 正好/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0\n",
       "0                            比/O 黑人/O 碳头/O 牙刷/T 好用/S ?/O\n",
       "1          比/O 之前/O 坏/S 的/O 要/O 好/S 些/O ，/O 亮/O 一些/O 。/O\n",
       "2          质量/T 很好/S 用/O 着/O 很/O 舒服/S 感觉/T 有点/O 小贵/S 啊/O\n",
       "3      发货/T 速度/T 很快/S ，/O 东西/T 收到/O 后/O 基本/O 上/O 和/O ...\n",
       "4      1/O 、/O 每/O 星期/O 至少/O 两/O 次/S 掉/O 线/T ，/O 一/O ...\n",
       "5                 从/O 中学/O 一直/O 在/O 用/O 的/O ，/O 质量/T 好/S\n",
       "6      此/O 产品/T 太/O 差劲/S 了/O ，/O 没有/O 任何/O 内/O 包装/T ，...\n",
       "7      色/O 粉笔/O 也/O 太贵/S 了/O 吧/O ，/O 而且/O 包装/T 也/O 有些...\n",
       "8      买/O 了/O 跟/O 老公/O 一/O 人/O 一个/O ，/O 用/O 下/O 来/O ...\n",
       "9      亚马逊/T 自营/T 的/O 东西/T 是/O 正品/S ，/O 一贯/O 都/O 不错/S...\n",
       "10                           气味/T 清香/S ，/O 洗衣/T 洁净/S 。/O\n",
       "11         中间/O 有/O 几/O 页/O 排版/T 有问题/S 有/O 的/O 字/T 看不到/S\n",
       "12            方便/S ，/O 可/O 挂脖/O 上/O ，/O 当/O 项链/O 了/O 。/O\n",
       "13     产品/T 挺软/O ，/O 不/O 过/O 孩子/O 更/O 喜欢/S 自己/O 手指头/O...\n",
       "14     4/O g/O 移动卡/O ，/O 插/O 进去/O 居然/O 没/O 任何/O 反应/T ...\n",
       "15     袜子/T 质量/T 很/O 不错/S ，/O 很/O 满意/S ，/O 这个/O 价/T 格...\n",
       "16     建议/O 看/O 原版/O 难怪/O 在/O 欧洲/O 销量/O 排行/O 第一/O 的/O...\n",
       "17     考试/O 内容/T 为0/O 最新/O 题库/O 里面/O 没有/O 一/O 道/O 题/O...\n",
       "18               rt/O ，/O 搞/O 个/O 驱动/O 太/O 麻烦/S ，/O 烦死/S\n",
       "19     卖/O 了/O 6/O 瓶/T ，/O 没有/O 一/O 瓶/T 不漏/S 的/O ，/O ...\n",
       "20                 1/O 。/O 现在/O 一直/O 还/O 在/O 用/O 。/O 。/O\n",
       "21     发/O 过/O 来/O 的/O 是/O 老/O 包装/T ，/O 但是/O 与/O 在/O ...\n",
       "22     1/O ./O 收到/O 货/T 以后/O 内部/O 包装盒/T 上/O 的/O 防伪/O ...\n",
       "23     用/O 了/O 一/O 周/O ，/O 主要/O 当/O 无/O 线路/T 由/O （/O ...\n",
       "24     好东西/S ，/O 绝对/O 物有所值/S ！/O 拿/O 回/O 来/O 三/O 天/O ...\n",
       "25     速度/T 没有/O 广告/T 的/O 那/O 么/O 大/O ，/O 实际/O 测量/T 应...\n",
       "26     我/O 买/O 的/O 亚马逊/T 直营/O ，/O 但是/O 送/O 来/O 的/O 外包...\n",
       "27     买/O 了/O 后/O ，/O 发现/O 公司/T 不/O 能/O 热/O 饭/O 了/O ...\n",
       "28     很好/S 用/O ，/O 是/O 正品/S ，/O 后悔/S 只/O 买/O 了/O 一/O...\n",
       "29     iFrogz/O 爱/O 蛙/O 音效/T 很/O 不错/S ，/O 价/T 格/O 很/O...\n",
       "...                                                  ...\n",
       "19970  这里/O 好多/O 的/O 托/O 啊/O ，/O 影响/O 了/O 我/O 的/O 判断/...\n",
       "19971  还/O 没/O 戴/O 着/O 滑雪/O ，/O 效果/T 好坏/O 还/O 不/O 知道/...\n",
       "19972  东西/T 没的说/S ，/O 我/O 家/O 儿子/O 一直/O 吃/O 皇/O 家/O 的...\n",
       "19973             很好/S ！/O 很好/S 用/O 哦/O ！/O 不/O 错哦/O ！/O\n",
       "19974                   内容/T 没有/O 意义/O ，/O 毫无/O 特色/O 。/O\n",
       "19975  里面/O 的/O 橡胶/T 搓搓/O 就/O 掉/O 了/O ，/O 做工/T 不/O 是/...\n",
       "19976  这个/O 有/O 直营/O 和/O 第三方/O 的/O 都/O 在/O 活动/O 或/O 参...\n",
       "19977  才/O 用/O 了/O 半/O 个/O 月/O ，/O 后面/O 丢/O 给/O 女朋友/O...\n",
       "19978  很好/S 用/O 很/O 实际/O 的/O 东西/T ，/O 赞/S 。/O 。/O 。/O...\n",
       "19979  味道/T 有点/O 浓/O ，/O 感觉/T 加/O 了/O 很多/S 香精/T ，/O 但...\n",
       "19980  估计/O 也/O 是/O 随机/O 发放/O 的/O 封面/T ，/O 收到/O 的/O 这...\n",
       "19981  买/O 的/O 虽然/O 有/O 一/O 年/O 了/O 、/O 但/O 基本/O 上/O ...\n",
       "19982               很好/S 跟/O 图片/T 相符/S ，/O 包装/T 完整/S 。/O\n",
       "19983           才/O 发现/O 发错货/O 了/O ，/O 发成/O 蓝色/O 的/O 了/O\n",
       "19984  东西/T 还行/S ，/O 便宜/S 又/O 好用/S 。/O 就/O 是/O 送货/T 时...\n",
       "19985  品胜/O 大/O 品牌/T ，/O 性/O 价/T 比/O 很高/S 。/O 电量/T 很足...\n",
       "19986                         有点/O 不稳/S 质量/T 还可以/S 还可以/S\n",
       "19987  还/O 没有/O 认真/S 的/O 研究/O ，/O 只/O 拿/O 出/O 来/O 把/O...\n",
       "19988                    脏兮兮/S 的/O 像/O 退/O 回去/O 的/O 旧书/O\n",
       "19989             还好/S ，/O 挺/O 不错/S 的/O ，/O 值得/S 、/O 、/O\n",
       "19990  自打/O 从/O 卓越/S 买/O 东西/T ，/O 到/O 现在/O 成为/O VIP/O...\n",
       "19991  中国/O PS术/O ，/O 自/O 诞生/O 以/O 来/O 教众/O 不/O 断/O ，...\n",
       "19992  应该/O 还可以/S ，/O 儿童/O 冬季/O 补点/O 还是/O 需要/O 吧/O ，/...\n",
       "19993  和/O 某/O 羊/O 品牌/T 的/O 电热/O 毯比/O ，/O 做工/T 还是/O 差...\n",
       "19994  做工/T 扎实/S ，/O 样子/T 漂亮/S ，/O 唯一/O 就是/O 有/O 点/O ...\n",
       "19995  P4/O …/O …/O 但/O 这/O 本/O 书/T 的/O 主要/O 目/O 的/O ...\n",
       "19996  说/O 的/O 是/O 176/O 长/S ，/O 想想/O 可以/S 够/O 一/O 人/...\n",
       "19997  一般/S ，/O 太软/S 了/O ，/O 躺/O 下去/O 扁扁/O 的/O ，/O 很低...\n",
       "19998                  很好/S 用/O ，/O 大/O 点/O 就/O 更好/S 了/O\n",
       "19999  183/O 70/O 穿/O L/O 正好/S 183/O 70/O 穿/O L/O 正好/...\n",
       "\n",
       "[20000 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = ['S', 'T', 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./data/target.csv', 'w') as target:\n",
    "    target.write(str(res))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
