{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 数据可视化\n",
    "# import matplotlib.pyplot as plt\n",
    "# df_data['sentence_len'].hist(bins=100)\n",
    "# plt.xlim(0, 100)\n",
    "# plt.xlabel('sentence_length')\n",
    "# plt.ylabel('sentence_num')\n",
    "# plt.title('Distribution of the Length of Sentence')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from itertools import chain\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# filename = './data/sentiment_word_tagging_train.csv'\n",
    "def word_to_index(sentence, flag, tokenizer):\n",
    "    res = []\n",
    "    if flag == 'content':\n",
    "        tmp = tokenizer.texts_to_sequences(sentence)\n",
    "        for i in tmp:\n",
    "            if i:\n",
    "                res.append(i[0])\n",
    "    else:\n",
    "        tag_dict = {'B':1, 'M':2, 'E':3, 'S':4, 'N':5}\n",
    "        for word in sentence:\n",
    "            res.append(tag_dict[word])\n",
    "    return [res]\n",
    "\n",
    "def get_Xy(sentence):\n",
    "    \"\"\"将 sentence 处理成 [word1, w2, ..wn], [tag1, t2, ...tn]\"\"\"\n",
    "    sentence = sentence.replace(\"//\", '$/')\n",
    "    words_tags = re.findall('(.)/(.)', sentence)\n",
    "    if words_tags:\n",
    "        words_tags = np.asarray(words_tags)\n",
    "        words = words_tags[:, 0]\n",
    "        tags = words_tags[:, 1]\n",
    "        return words, tags # 所有的字和tag分别存为 data / label\n",
    "    return None\n",
    "\n",
    "def initTokenizer():\n",
    "    df = pd.read_csv('./data/allwords.csv', dtype=np.str, header=None)\n",
    "    all_words = df[0].values\n",
    "    tokenizer = Tokenizer(lower=False)\n",
    "    tokenizer.fit_on_texts(all_words)\n",
    "    return tokenizer\n",
    "def generate_data(filename):\n",
    "    raw_data = pd.read_csv(filename, header=None, delimiter='\\t')\n",
    "    s = ''\n",
    "    for index, row in raw_data.iterrows():\n",
    "        if index != 0:\n",
    "            s = s + ' '\n",
    "        s = s + row.values[0]\n",
    "    sentences = re.split(u'[，。！？、‘’“”]/[BMENS]', s)\n",
    "    datas = []\n",
    "    labels = []\n",
    "    for sentence in iter(sentences):\n",
    "        res = get_Xy(sentence)\n",
    "        if res:\n",
    "            datas.append(res[0])\n",
    "            labels.append(res[1])\n",
    "    df_data = pd.DataFrame({'words': datas, 'tags': labels}, index=range(len(datas)))\n",
    "    #　句子长度\n",
    "    df_data['sentence_len'] = df_data['words'].apply(lambda words: len(words))\n",
    "\n",
    "\n",
    "    tokenizer = initTokenizer()\n",
    "    df_data['X'] = df_data['words'].apply(word_to_index, args = ['content', tokenizer])\n",
    "    df_data['Y'] = df_data['tags'].apply(word_to_index, args = ['sentiment', tokenizer])\n",
    "    print(\"finish word_to_index\")\n",
    "    \n",
    "    maxlen = 40\n",
    "    df_data['X'] = df_data['X'].apply(pad_sequences, args=[maxlen, 'int32', 'post'])\n",
    "    df_data['Y'] = df_data['Y'].apply(pad_sequences, args=[maxlen, 'int32', 'post'])\n",
    "    \n",
    "    X = np.asarray(list(df_data['X'].values))\n",
    "    y = np.asarray(list(df_data['Y'].values))\n",
    "    X = X.reshape(X.shape[0], X.shape[2])\n",
    "    y = y.reshape(y.shape[0], y.shape[2])\n",
    "    \n",
    "    #将标签向量one-hot\n",
    "    def getY(y):\n",
    "        res = []\n",
    "        for row in y:\n",
    "            tmp = []\n",
    "            for col in row:\n",
    "                tmp.append(np_utils.to_categorical(col, 6))\n",
    "            res.append(tmp)\n",
    "        return np.array(res)\n",
    "    y = getY(y)\n",
    "    y = y.reshape(-1, 40, 6)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish word_to_index\n"
     ]
    }
   ],
   "source": [
    "X, y = generate_data('./data/sentiment_word_tagging_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 40\n",
    "word_size = 128\n",
    "from keras.layers import Dense, Embedding, LSTM, TimeDistributed, Input, Bidirectional\n",
    "from keras.models import Model\n",
    "\n",
    "sequence = Input(shape=(maxlen,), dtype='int32')\n",
    "embedded = Embedding(len(all_words)+1, word_size, input_length=maxlen, mask_zero=True)(sequence)\n",
    "blstm = Bidirectional(LSTM(64, return_sequences=True), merge_mode='sum')(embedded)\n",
    "output = TimeDistributed(Dense(6, activation='softmax'))(blstm)\n",
    "model = Model(input=sequence, output=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 1024\n",
    "history = model.fit(X, y, batch_size=batch_size, epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5728/5728 [==============================] - 3s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.25671975493597587, 0.91665562338003237]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('./model/sentiment_model.hdf5')\n",
    "model.predict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 90,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([X[0]])\n",
    "\n",
    "y1 = y[0]\n",
    "predict = model.predict(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = predict.reshape(40, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.76341156e-04,   8.56741488e-01,   2.01830436e-02,\n",
       "          1.45407394e-03,   2.97523191e-04,   1.21147558e-01],\n",
       "       [  4.59006010e-03,   1.69442650e-02,   4.09273691e-02,\n",
       "          8.89589727e-01,   1.18091851e-02,   3.61393802e-02],\n",
       "       [  7.62225222e-03,   1.04676122e-02,   5.20272665e-02,\n",
       "          8.52759242e-01,   1.55924875e-02,   6.15311526e-02],\n",
       "       [  7.62225222e-03,   1.04676122e-02,   5.20272665e-02,\n",
       "          8.52759242e-01,   1.55924875e-02,   6.15311526e-02],\n",
       "       [  7.62225222e-03,   1.04676122e-02,   5.20272665e-02,\n",
       "          8.52759242e-01,   1.55924875e-02,   6.15311526e-02],\n",
       "       [  7.62225222e-03,   1.04676122e-02,   5.20272665e-02,\n",
       "          8.52759242e-01,   1.55924875e-02,   6.15311526e-02],\n",
       "       [  7.62225222e-03,   1.04676122e-02,   5.20272665e-02,\n",
       "          8.52759242e-01,   1.55924875e-02,   6.15311526e-02],\n",
       "       [  7.62225222e-03,   1.04676122e-02,   5.20272665e-02,\n",
       "          8.52759242e-01,   1.55924875e-02,   6.15311526e-02],\n",
       "       [  7.62225222e-03,   1.04676122e-02,   5.20272665e-02,\n",
       "          8.52759242e-01,   1.55924875e-02,   6.15311526e-02],\n",
       "       [  7.62225222e-03,   1.04676122e-02,   5.20272665e-02,\n",
       "          8.52759242e-01,   1.55924875e-02,   6.15311526e-02]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = []\n",
    "for row in predict:\n",
    "    res.append(np.argmax(row))\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.76341156e-04,   8.56741488e-01,   2.01830436e-02,\n",
       "         1.45407394e-03,   2.97523191e-04,   1.21147558e-01], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
